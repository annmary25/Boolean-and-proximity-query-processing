{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_text = glob.glob('/home/deepcompute/ann_mary_shaju/IR/Entertainment/*.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1053\n"
     ]
    }
   ],
   "source": [
    "print(len(all_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {}\n",
    "i = 0\n",
    "for text in all_text:\n",
    "    with open(text, \"r\", encoding = \"latin1\") as file:\n",
    "        data[i] = file.readlines()\n",
    "        i = i + 1\n",
    "    data[i-1] = [\" \".join(data[i-1]), i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pandas.DataFrame(data).T\n",
    "data.columns = ['Text', 'Doc ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1053, 2)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Doc ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n In article &lt;artmel.735538777@well.sf.ca.us&gt;...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Distribution: na\\n Message-ID: &lt;1r77ph$66i@acc...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n In article &lt;C61rDq.5v5@chinet.chi.il.us&gt;, s...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\n In article &lt;strnlghtC5t3K6.InF@netcom.com&gt; ...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\\n : There are chips which perform the voice c...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>\\n In &lt;C5x2xs.EF0@lerami.lerctr.org&gt; merlin@le...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>\\n    For example, I don't own a cordless phon...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Distribution: world\\n Message-ID: &lt;1r1om5$c5m@...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>\\n In article &lt;1qnmnp$db8@sol.TIS.COM&gt; mjr@tis...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>\\n \\n In article &lt;strnlghtC5yBKA.Dp5@netcom.co...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Doc ID\n",
       "0  \\n In article <artmel.735538777@well.sf.ca.us>...      1\n",
       "1  Distribution: na\\n Message-ID: <1r77ph$66i@acc...      2\n",
       "2  \\n In article <C61rDq.5v5@chinet.chi.il.us>, s...      3\n",
       "3  \\n In article <strnlghtC5t3K6.InF@netcom.com> ...      4\n",
       "4  \\n : There are chips which perform the voice c...      5\n",
       "5  \\n In <C5x2xs.EF0@lerami.lerctr.org> merlin@le...      6\n",
       "6  \\n    For example, I don't own a cordless phon...      7\n",
       "7  Distribution: world\\n Message-ID: <1r1om5$c5m@...      8\n",
       "8  \\n In article <1qnmnp$db8@sol.TIS.COM> mjr@tis...      9\n",
       "9  \\n \\n In article <strnlghtC5yBKA.Dp5@netcom.co...     10"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1053 entries, 0 to 1052\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Text    1053 non-null   object\n",
      " 1   Doc ID  1053 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 24.7+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1048"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique = list(data.Text.unique())\n",
    "len(unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1048, 2)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sort_values(\"Text\", inplace = True)\n",
    "data.drop_duplicates(subset =\"Text\", keep = \"first\", inplace = True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Doc ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td></td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>\\n</td>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>\\n \\t\\tI think I should also point out that th...</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>\\n \\t  The points raised about checking what i...</td>\n",
       "      <td>647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>\\n \\tActually, many of us have noted this. We ...</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>\\n \\tDoes anyone out there know of any ftp sit...</td>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>\\n \\tEven more interesting: the SMTP server at...</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>\\n \\tFrom: \"dan mckinnon\" &lt;dan.mckinnon@canrem...</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>\\n \\tFrom: Marc VanHeyningen &lt;mvanheyn@cs.indi...</td>\n",
       "      <td>979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>\\n \\tFrom: andersom@spot.Colorado.EDU (Marc An...</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text Doc ID\n",
       "188                                                       189\n",
       "606                                                 \\n    607\n",
       "66   \\n \\t\\tI think I should also point out that th...     67\n",
       "646  \\n \\t  The points raised about checking what i...    647\n",
       "419  \\n \\tActually, many of us have noted this. We ...    420\n",
       "518  \\n \\tDoes anyone out there know of any ftp sit...    519\n",
       "264  \\n \\tEven more interesting: the SMTP server at...    265\n",
       "232  \\n \\tFrom: \"dan mckinnon\" <dan.mckinnon@canrem...    233\n",
       "978  \\n \\tFrom: Marc VanHeyningen <mvanheyn@cs.indi...    979\n",
       "313  \\n \\tFrom: andersom@spot.Colorado.EDU (Marc An...    314"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Doc ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td></td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>\\n</td>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>\\n \\t\\tI think I should also point out that th...</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>\\n \\t  The points raised about checking what i...</td>\n",
       "      <td>647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>\\n \\tActually, many of us have noted this. We ...</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>\\n \\tDoes anyone out there know of any ftp sit...</td>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>\\n \\tEven more interesting: the SMTP server at...</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>\\n \\tFrom: \"dan mckinnon\" \\n \\n \\t   I have lu...</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>\\n \\tFrom: Marc VanHeyningen \\n \\n \\tThe major...</td>\n",
       "      <td>979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>\\n \\tFrom: andersom@spot.Colorado.EDU (Marc An...</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text Doc ID\n",
       "188                                                       189\n",
       "606                                                 \\n    607\n",
       "66   \\n \\t\\tI think I should also point out that th...     67\n",
       "646  \\n \\t  The points raised about checking what i...    647\n",
       "419  \\n \\tActually, many of us have noted this. We ...    420\n",
       "518  \\n \\tDoes anyone out there know of any ftp sit...    519\n",
       "264  \\n \\tEven more interesting: the SMTP server at...    265\n",
       "232  \\n \\tFrom: \"dan mckinnon\" \\n \\n \\t   I have lu...    233\n",
       "978  \\n \\tFrom: Marc VanHeyningen \\n \\n \\tThe major...    979\n",
       "313  \\n \\tFrom: andersom@spot.Colorado.EDU (Marc An...    314"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing html tags\n",
    "from bs4 import BeautifulSoup\n",
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "data['Text'] = data['Text'].apply(lambda x: strip_html(x))\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Doc ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td></td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>\\n</td>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>\\n \\t\\tI think I should also point out that th...</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>\\n \\t  The points raised about checking what i...</td>\n",
       "      <td>647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>\\n \\tActually, many of us have noted this. We ...</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>\\n \\tDoes anyone out there know of any ftp sit...</td>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>\\n \\tEven more interesting: the SMTP server at...</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>\\n \\tFrom: \"dan mckinnon\" \\n \\n \\t   I have lu...</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>\\n \\tFrom: Marc VanHeyningen \\n \\n \\tThe major...</td>\n",
       "      <td>979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>\\n \\tFrom: andersom@spot.Colorado.EDU (Marc An...</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text Doc ID\n",
       "188                                                       189\n",
       "606                                                 \\n    607\n",
       "66   \\n \\t\\tI think I should also point out that th...     67\n",
       "646  \\n \\t  The points raised about checking what i...    647\n",
       "419  \\n \\tActually, many of us have noted this. We ...    420\n",
       "518  \\n \\tDoes anyone out there know of any ftp sit...    519\n",
       "264  \\n \\tEven more interesting: the SMTP server at...    265\n",
       "232  \\n \\tFrom: \"dan mckinnon\" \\n \\n \\t   I have lu...    233\n",
       "978  \\n \\tFrom: Marc VanHeyningen \\n \\n \\tThe major...    979\n",
       "313  \\n \\tFrom: andersom@spot.Colorado.EDU (Marc An...    314"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing numbers\n",
    "import re\n",
    "def remove_numbers(text):\n",
    "  text = re.sub(r'\\d+', '', text)\n",
    "  return text\n",
    "\n",
    "data['Text'] = data['Text'].apply(lambda x: remove_numbers(x))\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting text to lower\n",
    "data['Text'] = data.apply(lambda row: row['Text'].lower(), axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/deepcompute/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /home/deepcompute/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /home/deepcompute/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize \n",
    "nltk.download('stopwords')  \n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords \n",
    "stop = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization of data\n",
    "data['Text'] = data.apply(lambda row: word_tokenize(row['Text']), axis=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Doc ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>[]</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>[]</td>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>[i, think, i, should, also, point, out, that, ...</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>[the, points, raised, about, checking, what, i...</td>\n",
       "      <td>647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>[actually, ,, many, of, us, have, noted, this,...</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>[does, anyone, out, there, know, of, any, ftp,...</td>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>[even, more, interesting, :, the, smtp, server...</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>[from, :, ``, dan, mckinnon, '', i, have, lurk...</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>[from, :, marc, vanheyningen, the, majority, o...</td>\n",
       "      <td>979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>[from, :, andersom, @, spot.colorado.edu, (, m...</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text Doc ID\n",
       "188                                                 []    189\n",
       "606                                                 []    607\n",
       "66   [i, think, i, should, also, point, out, that, ...     67\n",
       "646  [the, points, raised, about, checking, what, i...    647\n",
       "419  [actually, ,, many, of, us, have, noted, this,...    420\n",
       "518  [does, anyone, out, there, know, of, any, ftp,...    519\n",
       "264  [even, more, interesting, :, the, smtp, server...    265\n",
       "232  [from, :, ``, dan, mckinnon, '', i, have, lurk...    233\n",
       "978  [from, :, marc, vanheyningen, the, majority, o...    979\n",
       "313  [from, :, andersom, @, spot.colorado.edu, (, m...    314"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing non-ASCII characters from list of tokenized words\n",
    "import unicodedata\n",
    "\n",
    "def remove_non_ascii(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = unicodedata.normalize('NFKD', word).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "        new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "data['Text'] = data.apply(lambda row: remove_non_ascii(row['Text']), axis=1)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Doc ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>[]</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>[]</td>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>[i, think, i, should, also, point, out, that, ...</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>[the, points, raised, about, checking, what, i...</td>\n",
       "      <td>647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>[actually, many, of, us, have, noted, this, we...</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>[does, anyone, out, there, know, of, any, ftp,...</td>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>[even, more, interesting, the, smtp, server, a...</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>[from, dan, mckinnon, i, have, lurked, here, a...</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>[from, marc, vanheyningen, the, majority, of, ...</td>\n",
       "      <td>979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>[from, andersom, spotcoloradoedu, marc, anders...</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text Doc ID\n",
       "188                                                 []    189\n",
       "606                                                 []    607\n",
       "66   [i, think, i, should, also, point, out, that, ...     67\n",
       "646  [the, points, raised, about, checking, what, i...    647\n",
       "419  [actually, many, of, us, have, noted, this, we...    420\n",
       "518  [does, anyone, out, there, know, of, any, ftp,...    519\n",
       "264  [even, more, interesting, the, smtp, server, a...    265\n",
       "232  [from, dan, mckinnon, i, have, lurked, here, a...    233\n",
       "978  [from, marc, vanheyningen, the, majority, of, ...    979\n",
       "313  [from, andersom, spotcoloradoedu, marc, anders...    314"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing punctuations and special characters\n",
    "\n",
    "import re\n",
    "def remove_punctuations(words):\n",
    "    \"\"\"Remove punctuations from list of tokenized words\"\"\"\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_word = re.sub(r'[^\\w\\s]', '', word)\n",
    "        if new_word != '':\n",
    "            new_words.append(new_word)\n",
    "    return new_words\n",
    "\n",
    "\n",
    "data['Text'] = data.apply(lambda row: remove_punctuations(row['Text']), axis=1)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Doc ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>[]</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>[]</td>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>[think, also, point, mystical, des, engines, k...</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>[points, raised, checking, actually, chip, opp...</td>\n",
       "      <td>647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>[actually, many, us, noted, noted, program, st...</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>[anyone, know, ftp, sites, deal, electronics, ...</td>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>[even, interesting, smtp, server, csrcncslnist...</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>[dan, mckinnon, lurked, bit, lately, though, m...</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>[marc, vanheyningen, majority, discussion, inv...</td>\n",
       "      <td>979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>[andersom, spotcoloradoedu, marc, anderson, al...</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text Doc ID\n",
       "188                                                 []    189\n",
       "606                                                 []    607\n",
       "66   [think, also, point, mystical, des, engines, k...     67\n",
       "646  [points, raised, checking, actually, chip, opp...    647\n",
       "419  [actually, many, us, noted, noted, program, st...    420\n",
       "518  [anyone, know, ftp, sites, deal, electronics, ...    519\n",
       "264  [even, interesting, smtp, server, csrcncslnist...    265\n",
       "232  [dan, mckinnon, lurked, bit, lately, though, m...    233\n",
       "978  [marc, vanheyningen, majority, discussion, inv...    979\n",
       "313  [andersom, spotcoloradoedu, marc, anderson, al...    314"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing stop words\n",
    "def remove_stopwords(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        if word not in stop:\n",
    "            new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "data['Text'] = data.apply(lambda row: remove_stopwords(row['Text']), axis=1)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Doc ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>[]</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>[]</td>\n",
       "      <td>607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>[think, also, point, mystical, des, engines, k...</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>[point, raise, check, actually, chip, oppose, ...</td>\n",
       "      <td>647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>[actually, many, us, note, note, program, star...</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>[anyone, know, ftp, sit, deal, electronics, pr...</td>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>[even, interest, smtp, server, csrcncslnistgov...</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>[dan, mckinnon, lurk, bite, lately, though, ma...</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>[marc, vanheyningen, majority, discussion, inv...</td>\n",
       "      <td>979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>[andersom, spotcoloradoedu, marc, anderson, al...</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text Doc ID\n",
       "188                                                 []    189\n",
       "606                                                 []    607\n",
       "66   [think, also, point, mystical, des, engines, k...     67\n",
       "646  [point, raise, check, actually, chip, oppose, ...    647\n",
       "419  [actually, many, us, note, note, program, star...    420\n",
       "518  [anyone, know, ftp, sit, deal, electronics, pr...    519\n",
       "264  [even, interest, smtp, server, csrcncslnistgov...    265\n",
       "232  [dan, mckinnon, lurk, bite, lately, though, ma...    233\n",
       "978  [marc, vanheyningen, majority, discussion, inv...    979\n",
       "313  [andersom, spotcoloradoedu, marc, anderson, al...    314"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatizing data\n",
    "\n",
    "from nltk.stem.wordnet import WordNetLemmatizer         \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_list(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_words.append(lemmatizer.lemmatize(word, pos='v'))\n",
    "    return new_words\n",
    "\n",
    "data['Text'] = data.apply(lambda row: lemmatize_list(row['Text']), axis=1)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Doc ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>[think, also, point, mystical, des, engines, k...</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>[point, raise, check, actually, chip, oppose, ...</td>\n",
       "      <td>647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>[actually, many, us, note, note, program, star...</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>[anyone, know, ftp, sit, deal, electronics, pr...</td>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>[even, interest, smtp, server, csrcncslnistgov...</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>[dan, mckinnon, lurk, bite, lately, though, ma...</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>[marc, vanheyningen, majority, discussion, inv...</td>\n",
       "      <td>979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>[andersom, spotcoloradoedu, marc, anderson, al...</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>[brad, clarinetcom, brad, templeton, let, assu...</td>\n",
       "      <td>453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>[pmetzger, snarkshearsoncom, perry, e, metzger...</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text Doc ID\n",
       "66   [think, also, point, mystical, des, engines, k...     67\n",
       "646  [point, raise, check, actually, chip, oppose, ...    647\n",
       "419  [actually, many, us, note, note, program, star...    420\n",
       "518  [anyone, know, ftp, sit, deal, electronics, pr...    519\n",
       "264  [even, interest, smtp, server, csrcncslnistgov...    265\n",
       "232  [dan, mckinnon, lurk, bite, lately, though, ma...    233\n",
       "978  [marc, vanheyningen, majority, discussion, inv...    979\n",
       "313  [andersom, spotcoloradoedu, marc, anderson, al...    314\n",
       "452  [brad, clarinetcom, brad, templeton, let, assu...    453\n",
       "365  [pmetzger, snarkshearsoncom, perry, e, metzger...    366"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Removing empty texts\n",
    "for i in range(0,len(data['Text'])-1):\n",
    "    if len(data['Text'].iloc[i]) == 0:\n",
    "        data = data.drop(data.index[i])\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Doc ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>[think, think, also, also, point, point, mysti...</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>[point, point, rais, raise, check, check, actu...</td>\n",
       "      <td>647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>[actual, actually, mani, many, us, us, note, n...</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>[anyon, anyone, know, know, ftp, ftp, sit, sit...</td>\n",
       "      <td>519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>[even, even, interest, interest, smtp, smtp, s...</td>\n",
       "      <td>265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232</th>\n",
       "      <td>[dan, dan, mckinnon, mckinnon, lurk, lurk, bit...</td>\n",
       "      <td>233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>[marc, marc, vanheyningen, vanheyningen, major...</td>\n",
       "      <td>979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>[andersom, andersom, spotcoloradoedu, spotcolo...</td>\n",
       "      <td>314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>[brad, brad, clarinetcom, clarinetcom, brad, b...</td>\n",
       "      <td>453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>[pmetzger, pmetzger, snarkshearsoncom, snarksh...</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Text Doc ID\n",
       "66   [think, think, also, also, point, point, mysti...     67\n",
       "646  [point, point, rais, raise, check, check, actu...    647\n",
       "419  [actual, actually, mani, many, us, us, note, n...    420\n",
       "518  [anyon, anyone, know, know, ftp, ftp, sit, sit...    519\n",
       "264  [even, even, interest, interest, smtp, smtp, s...    265\n",
       "232  [dan, dan, mckinnon, mckinnon, lurk, lurk, bit...    233\n",
       "978  [marc, marc, vanheyningen, vanheyningen, major...    979\n",
       "313  [andersom, andersom, spotcoloradoedu, spotcolo...    314\n",
       "452  [brad, brad, clarinetcom, clarinetcom, brad, b...    453\n",
       "365  [pmetzger, pmetzger, snarkshearsoncom, snarksh...    366"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Normalizing the words using porter stemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def stemming(words):\n",
    "    new_words = []\n",
    "    for word in words:\n",
    "        new_words.append(ps.stem(word))\n",
    "        new_words.append(word)\n",
    "    return new_words\n",
    "\n",
    "data['Text'] = data.apply(lambda row: stemming(row['Text']), axis=1)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boolean Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverted index construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "inverted_index = {}\n",
    "\n",
    "for index,row in data.iterrows():\n",
    "    unique_terms_in_document = set(row['Text'])\n",
    "    for term in unique_terms_in_document:\n",
    "        if term not in inverted_index.keys():\n",
    "            inverted_index[term] = [row['Doc ID']]\n",
    "        else:\n",
    "            inverted_index[term].append(row['Doc ID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to process the given query\n",
    "def processing_query(query):\n",
    "    infix_tokens=word_tokenize(query)\n",
    "    precedence = {}\n",
    "    precedence['NOT'] = 3\n",
    "    precedence['AND'] = 3\n",
    "    precedence['OR'] = 3\n",
    "    precedence['('] = 2\n",
    "    precedence[')'] = 1\n",
    "              \n",
    "    output = []\n",
    "    operator_stack = []\n",
    " \n",
    "    for token in infix_tokens:\n",
    "        if (token.upper() == '('):\n",
    "            operator_stack.append(token)\n",
    "        elif (token.upper() == ')'):\n",
    "            operator = operator_stack.pop()\n",
    "            while operator != '(':\n",
    "                output.append(operator)\n",
    "                operator = operator_stack.pop()\n",
    " \n",
    "        elif (token.upper() in precedence):\n",
    "            if (operator_stack):\n",
    "                current_operator = operator_stack[-1]\n",
    "                while (operator_stack and precedence[current_operator.upper()] > precedence[token.upper()]):\n",
    "                    output.append(operator_stack.pop())\n",
    "                    if (operator_stack):\n",
    "                        current_operator = operator_stack[-1]\n",
    "            operator_stack.append(token)\n",
    "        else:\n",
    "            output.append(token.lower())\n",
    "    while (operator_stack):\n",
    "        output.append(operator_stack.pop())\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean retrieval implementation\n",
    "def boolean_retrieval(postfix):\n",
    "    boolean_op = ['AND', 'OR', 'NOT']\n",
    "    doc_list = []\n",
    "    query_list = []\n",
    "    for exp in postfix:\n",
    "        if exp in boolean_op:\n",
    "            if query_list or exp == 'NOT':\n",
    "                output = []\n",
    "                if exp == 'NOT':\n",
    "                    if query_list:\n",
    "                        query = query_list.pop()\n",
    "                        output = list(set(data['Doc ID'].tolist())-set(inverted_index[query]))\n",
    "                    else:\n",
    "                        doc_list = list(set(data['Doc ID'].tolist())-set(doc_list))\n",
    "                else:\n",
    "                    query1 = query_list.pop()\n",
    "                    if query_list:\n",
    "                        query2 = query_list.pop()\n",
    "                        if exp == 'AND':\n",
    "                            output = list(set(inverted_index[query1]) & set(inverted_index[query2]))\n",
    "                        if exp == 'OR':\n",
    "                            output = list(set(inverted_index[query1]) | set(inverted_index[query2]))\n",
    "                        doc_list = doc_list + output\n",
    "                    else:\n",
    "                        if exp == 'AND':\n",
    "                            doc_list = list(set(doc_list) & set(inverted_index[query1]))\n",
    "                        if exp == 'OR':\n",
    "                            doc_list = list(set(doc_list) | set(inverted_index[query1]))            \n",
    "        else:\n",
    "            query_list.append(exp)\n",
    "    doc_list.sort()\n",
    "    return doc_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boolean retrieval Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the query (Please mention the boolean queries as AND, OR, NOT): NOT(MARCUS OR anderson) AND (NOT POINT AND NOT ALSO)\n",
      "\n",
      "Given query:  NOT(MARCUS OR anderson) AND (NOT POINT AND NOT ALSO)\n",
      "\n",
      "Documents in which the given query is present is\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[715, 788, 828]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = input('Enter the query (Please mention the boolean queries as AND, OR, NOT): ')\n",
    "processed_query = processing_query(query) \n",
    "print(\"\\nGiven query: \", query)\n",
    "print(\"\\nDocuments in which the given query is present is\")\n",
    "boolean_retrieval(processed_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phrase queries and proximity queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional Index Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "positional_index = {}\n",
    "\n",
    "for index,row in data.iterrows():\n",
    "    index = 0\n",
    "    for term in row['Text']:\n",
    "        if term not in positional_index.keys():\n",
    "            positional_index[term] = {}\n",
    "            positional_index[term][row['Doc ID']] = [i]\n",
    "        else:\n",
    "            if row['Doc ID'] in positional_index[term].keys():\n",
    "                positional_index[term][row['Doc ID']].append(i)\n",
    "            else:\n",
    "                positional_index[term][row['Doc ID']] = [i]\n",
    "        i = i + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROXIMITY QUERY IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter input query1: SENDER\n",
      "Enter input query2: news\n",
      "Enter the proximity: 5\n"
     ]
    }
   ],
   "source": [
    "query1 = (input(\"Enter input query1: \")).lower()\n",
    "query2 = (input(\"Enter input query2: \")).lower()\n",
    "proximity = int(input(\"Enter the proximity: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the documents in which both queries are present\n",
    "\n",
    "if query1 in positional_index.keys():\n",
    "    query1_doc = set(positional_index[query1].keys())\n",
    "if query2 in positional_index.keys():\n",
    "    query2_doc = set(positional_index[query2].keys())\n",
    "\n",
    "# Documents in which query1 and query2 is present\n",
    "query1_and_query2_document = query1_doc & query2_doc\n",
    "\n",
    "resultant_dict = {}\n",
    "for document in query1_and_query2_document:\n",
    "    q1_positions, q1_position_len = positional_index[query1][document], len(positional_index[query1][document])\n",
    "    q2_positions, q2_position_len = positional_index[query2][document], len(positional_index[query1][document])\n",
    "    if q1_position_len <= q2_position_len:\n",
    "        for position in q1_positions:\n",
    "            proximity_list = []\n",
    "            proximity_list = [x for x in range(position-proximity,position+proximity+1)]\n",
    "            for query_2_position in q2_positions:\n",
    "                if query_2_position in proximity_list:\n",
    "                    if document not in resultant_dict.keys():\n",
    "                        resultant_dict[document] = {}\n",
    "                    if position in resultant_dict.keys():\n",
    "                        resultant_dict[document][position].append(query_2_position)\n",
    "                    else:\n",
    "                        resultant_dict[document][position] = [query_2_position]  \n",
    "    else:\n",
    "        for position in q2_positions:\n",
    "            proximity_list = []\n",
    "            proximity_list = [x for x in range(position-proximity,position+proximity+1)]\n",
    "            for query_1_position in q1_positions:\n",
    "                if query_1_position in proximity_list:\n",
    "                    if document not in resultant_dict.keys():\n",
    "                        resultant_dict[document] = {}\n",
    "                    if query_1_position in resultant_dict.keys():\n",
    "                        resultant_dict[document][query_1_position].append(position)\n",
    "                    else:\n",
    "                        resultant_dict[document][query_1_position] = [position]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents having sender and news within 5 words of each other and there positions are,\n",
      "\n",
      "\n",
      "Document ID: 899\n",
      "\tsender position - 344037 and news position - [344040] \n",
      "\tsender position - 344038 and news position - [344043] \n",
      "\n",
      "\n",
      "Document ID: 838\n",
      "\tsender position - 340561 and news position - [340564] \n",
      "\tsender position - 340562 and news position - [340567] \n",
      "\n",
      "\n",
      "Document ID: 808\n",
      "\tsender position - 138375 and news position - [138378] \n",
      "\tsender position - 138376 and news position - [138378] \n",
      "\n",
      "\n",
      "Document ID: 711\n",
      "\tsender position - 344563 and news position - [344566] \n",
      "\tsender position - 344564 and news position - [344569] \n",
      "\n",
      "\n",
      "Document ID: 345\n",
      "\tsender position - 344263 and news position - [344266] \n",
      "\tsender position - 344264 and news position - [344269] \n",
      "\n",
      "\n",
      "Document ID: 108\n",
      "\tsender position - 343855 and news position - [343858] \n",
      "\tsender position - 343856 and news position - [343861] \n",
      "\n",
      "\n",
      "Document ID: 496\n",
      "\tsender position - 344435 and news position - [344438] \n",
      "\tsender position - 344436 and news position - [344441] \n",
      "\n",
      "\n",
      "Document ID: 338\n",
      "\tsender position - 344791 and news position - [344794] \n",
      "\tsender position - 344792 and news position - [344794] \n",
      "\n",
      "\n",
      "Document ID: 1017\n",
      "\tsender position - 340279 and news position - [340282] \n",
      "\tsender position - 340280 and news position - [340285] \n",
      "\n",
      "\n",
      "Document ID: 767\n",
      "\tsender position - 343633 and news position - [343636] \n",
      "\tsender position - 343634 and news position - [343639] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Documents having {} and {} within {} words of each other and there positions are,\".format(query1,query2,proximity))\n",
    "print(\"\\n\")\n",
    "for key, value in resultant_dict.items():\n",
    "    print(\"Document ID:\",key)\n",
    "    for k, v in value.items():\n",
    "        print(\"\\t{} position - {} and {} position - {} \".format(query1,k,query2,v))\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall = (# relevant documents retrieved/ total # of relevant documents) \n",
    "\n",
    "\n",
    "Precision = (# relevant documents retrieved/ total # of documents retrieved)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
